{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NoLocal","text":""},{"location":"#what","title":"What","text":"<p>This is a work in progress bot for discord. In the time writing this, the bot is only capable of some silly commands.</p> <p>But it has a great infrastructure to create and deploy a bot in few steps! you can see de details in the full documentation.</p>"},{"location":"#why","title":"Why","text":"<p>The intention of this project is being a sandbox to experiment technologies, features, and more on a fully productive environment. </p> <p>All the development is using free tools and services, so it's a great way to create a discord bot free of charge with high monitoring, infrastructure, CI/CD, etc...</p>"},{"location":"#how","title":"How","text":"<p>You can check out the full documentation in this site</p>"},{"location":"#can-i-fork-it-and-have-my-own-bot","title":"Can I fork it and have my own bot?","text":"<p>Sure, that would be ideal.</p> <p>However, although there is a general documentation explaining all necessary integrations, It may be too hard to install it without an specific guide.</p> <p>It should be as simple as fork it and change the secrets and environment settings for your own.</p>"},{"location":"devguide/","title":"Quickstart","text":""},{"location":"devguide/#the-big-picture","title":"The Big Picture","text":""},{"location":"devguide/#tech-stack","title":"Tech stack","text":"Technology Type Description Reference Kotlin Language Modern JVM based language with full java compatibility Link Spring Boot Framework Robust and known framework to make the magic happens :) Link Gradle Build Tool Tool to build the project, with all the tasks related to compile, test and more Link Github Actions CI/CD Tool to orchestrate the checks, deploy and everything happening after a commit Link Sonarcloud Quality Analysis Tool to analyse the project to detect quality improvements (code smells, bugs...) Link Codecov Coverage Analysis Tool to show the testing coverage and its evolution Link MkDocs Static site generator Tool to generate a static site for documentation Link Oracle Cloud Hosting Cloud provider of this service deployment (free tier) Link Uptime Robot Monitoring Monitor to check the health of the application periodically by external http calls Link New Relic Monitoring Advanced monitoring from application metrics and log ingestion using a java agent Link"},{"location":"devguide/#building-it","title":"Building it","text":"<p>To build the executable jar, just run:</p> <pre><code>./gradlew build\n</code></pre> <p>This command will generate the jar output under build/libs</p>"},{"location":"devguide/#running-it","title":"Running it","text":"<p>Just do:</p> <pre><code>./gradlew bootRun\n</code></pre> <p>Or even simplier</p> <pre><code>java -jar nolocal.jar\n</code></pre>"},{"location":"devguide/#testing-it","title":"Testing it","text":"<p>All the tests are under the check task in gradle, so to run all the suite run:</p> <pre><code>./gradlew check\n</code></pre>"},{"location":"devguide/#integration-testing","title":"Integration testing","text":"<p>Integration tests are mixed with the unit tests, but on the infrastructure package. Originally, there was a split creating a separate module for the integration tests, but maintaining the gradle file was more difficult than the actual benefits of having it separated.</p>"},{"location":"devguide/#mutation-testing","title":"Mutation testing","text":"<p>You can run the mutation testing too! to do that, simply run</p> <pre><code>./gradlew pitest\n</code></pre> <p>This will generate a report under build/reports/pitest/</p> <p>In addition to this, the project has a job to generate the pitest report from  GitHub</p>"},{"location":"devguide/addingCommands/","title":"Adding commands","text":""},{"location":"devguide/addingCommands/#registering-commands","title":"Registering commands","text":"<p>To make a command available in the server it's needed to register it in the discord API. It can be registered as a global or a specific server command.</p> <p>This process is not automated, as the time of writing this, the process is as simple as to make a POST request with the  command specification. You can check the specific documentation in the following link</p>"},{"location":"devguide/addingCommands/#programming-slash-commands","title":"Programming slash commands","text":"<p>Adding commands is pretty straightforward.</p> <p>You just have to create a Spring bean. The name of the bean must be the command to listen. This bean has to implement the following interface:</p> <pre><code>com.datocal.nolocal.infrastructure.commands.DiscordCommand\n</code></pre> <p>For example, this would be a ping command:</p> <pre><code>@Component(\"ping\")\nclass PingCommand(private val ping: Ping) : DiscordCommand {\n\n    override fun accept(interaction: Interaction): InteractionResponse {\n        return InteractionResponse(ping.ping())\n    }\n}\n</code></pre> <p>And, for the discord registration to work, it must be documented with the @Command annotation. Description cannot be  informed for message commands.</p> <pre><code>@Command(\n    command = \"ping\",\n    description = \"Just a ping command\",\n    type = Command.TYPE_CHAT_INPUT,\n)\n</code></pre> <p>The notation @Component(\"ping\") will create the infrastructure necessary to create the bean and call this Runner when the  ping command is invoked. You just have to implement the method returning an InteractionResponse.</p> <p>The notation @Command will add the command to discord at startup if it's not already in the discord configuration.</p>"},{"location":"devguide/addingCommands/#how-the-magic-works","title":"How the magic works","text":"<p>The annotation @Component is a spring annotation. For those not familiarized with spring, this will initialize this class calling its constructor and put it in a magic box to take it any time it's needed in a program.</p> <p>In the shadows, Spring will create a Map with all the beans of type DiscordCommand  in the application, using the bean name (the command string in this case) as the key. We will use this to map any  command received to this bean. <p>To use the map, there is a controller who listens for upcoming commands, the interactions endpoint</p> <pre><code>@RestController\nclass InteractionsController(\n    private val commands: Map&lt;String, DiscordCommand&gt;\n) {\n\n    @PostMapping(\"/discord/interactions\")\n    fun execute(@RequestBody interaction: Interaction): InteractionResponse {\n        return commands[interaction.command]?.accept(interaction) ?: defaultResponse()\n    }\n\n    //ACK Discord PING checks\n    private fun defaultResponse() = InteractionResponse()\n}\n</code></pre> <p>Discord requires this endpoint to receive upcoming commands. In production, this endpoint is protected by a reverse proxy to only allow requests coming from discord. The proxy will require a header with the request encrypted with a private  key owned by discord.</p> <p>This class is located at the following package:</p> <pre><code>com.datocal.nolocal.infrastructure.discord.controller.InteractionsController\n</code></pre> <p>The registration on commands via discord works by a bean with a @PostConstruct annotation that register the command via api, using the class in:</p> <pre><code>com.datocal.nolocal.infrastructure.discord.CommandRegistrator\n</code></pre>"},{"location":"devguide/c4model/","title":"C4 model","text":"Structurizr - Name [System Landscape] (#nolocal)[Container] NoLocal (#Containers)[Component] NoLocal - NoLocalApp (#Components)[Deployment] NoLocal - Development (#NoLocal-Development-Deployment)[Deployment] NoLocal - Live (#NoLocal-Live-Deployment) Thursday, 10 November 2022 at 21:40 Central European Standard TimeSystemLandscape[System Landscape]User[Person]A discord userDiscord[Software System]Discord official system-NoLocal[Software System]Discord bot system+Respondcommands using--Remove vertex.Remove link.Link options.Send commandusing--Remove link.Link options.Registercommands using--Remove vertex.Remove link.Link options.PersonSoftware SystemSoftware System, DiscordRelationshipThursday, 10 November 2022 at 21:40 Central European Standard Time[Container] NoLocalNoLocal[Software System]Discord[Software System]Discord official system-Caddy[Container: Open source webserver written inGo, verifies Ed25519 signature]Reverse proxy with SSL-Redis[Container: Open source in memory datastore]Data Store-S3FS[Container: FUSE-based file system backed byAmazon S3]Engine to mount S3 like buckets-File system[Container]Mounted storage to save snapshotsin-Bucket[Container]S3-like bucket usingOracle Object Storage-NoLocalApp[Container: Kotlin &amp; Spring boot botapplication]Provides commands to execute+Registercommands using--Remove link.Link options.Redirects trafficusing--Remove vertex.Remove link.Link options.Respondcommands using--Remove vertex.Remove link.Link options.Stores data using--Remove link.Link options.Sends commandsusing--Remove vertex.Remove link.Link options.Syncronizesvolume using--Remove link.Link options.Synchronizes itsdata using--Remove link.Link options.Persistssnapshots using--Remove link.Link options.BucketCaddyElementNoLocalAppRedisSoftware System, DiscordVolumeRelationshipThursday, 10 November 2022 at 21:40 Central European Standard Time[Component] NoLocal - NoLocalAppNoLocalApp[Container]application[Component]-infrastructure[Component]-discord[Component]-Discord[Software System]Discord official system-Caddy[Container: Open source webserver written inGo, verifies Ed25519 signature]Reverse proxy with SSL-Redis[Container: Open source in memory datastore]Data Store-model[Component]-Registercommands using--Remove link.Link options.Respondcommands using--Remove link.Link options.Communicateswith discordusing--Remove vertex.Remove link.Link options.Stores data &amp;communicateswith discordusing--Remove vertex.Remove link.Link options.Manage usecases using--Remove link.Link options.Stores data using--Remove vertex.Remove link.Link options.Respondcommands using--Remove vertex.Remove link.Link options.Send commandsusing--Remove vertex.Remove link.Link options.Sends commandsusing--Remove vertex.Remove vertex.Remove link.Link options.CaddyElementRedisSoftware System, DiscordRelationshipThursday, 10 November 2022 at 21:40 Central European Standard Time[Deployment] NoLocal - DevelopmentDeveloper's Computer[Deployment Node: Windows/Ubuntu/MacOS....]-Discord System[Deployment Node]-Discord[Software System]Discord official systemNoLocalApp[Container: Kotlin &amp; Spring boot botapplication]Provides commands to executeRedis[Container: Open source in memory datastore]Data StoreStores data using--Remove link.Link options.Registercommands using--Remove vertex.Remove link.Link options.ElementNoLocalAppRedisSoftware System, DiscordRelationshipThursday, 10 November 2022 at 21:40 Central European Standard Time[Deployment] NoLocal - LiveOracle Cloud[Deployment Node]-Discord System[Deployment Node]-nolocal-instance[Deployment Node: Ubuntu 20.04 LTS]-Oracle Object Storage[Deployment Node]-Bucket[Container]S3-like bucket usingOracle Object StorageCaddy[Container: Open source webserver written inGo, verifies Ed25519 signature]Reverse proxy with SSLNoLocalApp[Container: Kotlin &amp; Spring boot botapplication]Provides commands to executeDiscord[Software System]Discord official systemRedis[Container: Open source in memory datastore]Data StoreFile system[Container]Mounted storage to save snapshotsinS3FS[Container: FUSE-based file system backed byAmazon S3]Engine to mount S3 like bucketsSends commandsusing--Remove vertex.Remove link.Link options.Registercommands using--Remove vertex.Remove link.Link options.Stores data using--Remove link.Link options.Respondcommands using--Remove vertex.Remove link.Link options.Persistssnapshots using--Remove link.Link options.Synchronizes itsdata using--Remove link.Link options.Syncronizesvolume using--Remove link.Link options.Redirects trafficusing--Remove vertex.Remove link.Link options.BucketCaddyElementNoLocalAppRedisSoftware System, DiscordVolumeRelationship"},{"location":"devguide/persistence/","title":"Persistence","text":"<p>Persistence is done by a redis container. Redis has multiple strategies to write data to disk. The chosen one is the default persistence, Redis Database (RDB).  By default it will save snapshots of the dataset each 60 seconds. It may seem weak, but it should not be an issue at all, worst case scenario would be a lost of 60 seconds of data and with few users it will be acceptable.</p> <p>However, having the redis dockerized inside a Virtual Machine forces to maintain a process to keep the data in another point to be able to destroy the machine and create another. That's where several technologies come into play:</p> <ul> <li>Redis: The official redis image from dockerhub.</li> <li>Oracle Object Storage: AWS S3 like bucket. Used to store the redis dumps.</li> <li>S3FS: Tool to mount S3 buckets into a file system.</li> <li>Docker volumes: A volume is created from a container using s3fs linking the host with the bucket. Another mount is  made to link that host's folder to the redis container.</li> </ul> <p></p> <p>Related info:  * Overview of Object Storage: https://docs.oracle.com/en-us/iaas/Content/Object/Concepts/objectstorageoverview.htm  * Mounting Object Storage buckets using s3fs: https://docs.oracle.com/en-us/iaas/Content/Object/Tasks/s3compatibleapi.htm#Supported_Amazon_S3_Clients  * Official s3fs-fuse repository: https://github.com/s3fs-fuse/s3fs-fuse  * Dockerized s3fs-fuse implementation: https://github.com/efrecon/docker-s3fs-client</p>"},{"location":"devguide/persistence/#compose-explanation","title":"Compose explanation","text":"<p>The following code is a valid configuration to use the bucket as a volume: </p> <pre><code>  s3fs:\n    image: 'efrecon/s3fs:1.91'\n    container_name: s3fs\n    devices:\n      - /dev/fuse\n    cap_add:\n      - SYS_ADMIN\n    security_opt:\n      - 'apparmor:unconfined'\n    stop_signal: SIGINT\n    volumes:\n      - '/mnt/nolocal:/opt/s3fs/bucket:rshared'\n    environment:\n      - AWS_S3_BUCKET\n      - AWS_S3_MOUNT\n      - AWS_S3_ACCESS_KEY_ID\n      - AWS_S3_SECRET_ACCESS_KEY\n      - AWS_S3_URL\n      - S3FS_ARGS\n      - S3FS_DEBUG\n      - UID\n      - GID\n</code></pre> <ul> <li>image: The image version generated automatically based on the s3fs implementation, so it will keep up to date.</li> <li>devices, cap_add &amp; security_opt: Make sure the container will be able to make availablo the S3 bucket</li> <li>stop_signal: By default, this image is prepared to be launched by docker-run, so it waits for the Ctrl+C (SIGINT) signal. Docker compose automatically sends SIGTERM on docker termination (by for example, a docker-compose stop command) This way the signal is overwritten and the container handles the termination correctly. Failing to do so will leave the mount in an inconsistent state.</li> <li>volumes: The left one will be the host mount point while de right one the docker one.  rshared makes the volume available to the host and other containers.</li> <li>environment: Some of them are explained on the secrets section. For the other ones:</li> <li>S3FS_ARGS: Two options are passed to S3FS:<ul> <li>use_path_request_style: Mandatory to use S3-compatible implementations instead of an AWS S3 official bucket</li> <li>allow_other: Used to be able to access the mount outside the s3fs container.</li> </ul> </li> <li>UID &amp; GID: UID &amp; GID of the redis user and group created in the redis container. This will make a chown and will    let redis access to the mount.</li> </ul>"},{"location":"devguide/security/","title":"Security","text":"<p>In order to be validated by discord, the implemented interactions endpoint must validate that the invocation is coming from discord.</p> <p>The full details about how discord send messages and how to validate them can be found in their official documentation</p> <p>To implement this, a caddy service is set up using the CarsonHoffman mod for caddy.</p> <p>The Caddy reverse proxy will check the calls to the interactions endpoint veryfing  the headers to ensure the call is made from discord.</p> <p>The modified caddy has been built and uploaded to the docker hub</p>"},{"location":"devguide/ci/","title":"Quick View","text":"<p>This project contains a full pipeline from 0 to production using Github Actions.</p> <p>There is a bunch of pipelines configured but the important one is the pipeline-jobs pipeline.</p> <ul> <li>Generate Docs: This pipeline only generates the docs. But the main one generates them too when pushing to master, so it's useless</li> <li>Mutation Tests: This pipeline runs the mutation tests and generates a report showing the real coverage.</li> <li>CI: This is the main pipeline with parallel jobs, infrastructure creation and deploy to production.</li> <li>Termination: This pipeline terminates all the resources in the cloud.</li> <li>pages-build-deployment: Pipeline generated by the buildDocs step on the main pipeline to deploy the documentation on gh pages.</li> </ul> <p>The following image shows the current jobs for the main pipeline:</p> <p></p>"},{"location":"devguide/ci/#generated-artifacts","title":"Generated artifacts","text":"<ul> <li>compose: The docker-compose file. Used in the deployment to launch the docker images</li> <li>documentation: The documentation site in a compressed zip file.</li> <li>artifact: The jar containing the NoLocal Spring Boot application.</li> </ul>"},{"location":"devguide/ci/configuration/","title":"CI configuration","text":"<p>All the non related infrastructure configuration is managed by the secrets explained in the previous section The following section contains the configuration needed on the python pipeline to create the infrastructure in the oracle cloud.</p> <p>The configuration is stored at the pipeline/config.py file.</p>"},{"location":"devguide/ci/configuration/#compartment","title":"Compartment","text":"<p>The compartment will be the root of all the resources created for this application.  The organization in the cloud infrastructure is divided into compartments to organize resources. </p> <p>It's created / deleted based on its name in the COMPARTMENT_NAME variable. </p> <p>Creating a custom compartment allows to isolate the application resources from the rest of the cloud resources we may be using in the account.</p> <p>On creation/getting it from the existing ones by name, it will use an OCID like this:</p> <pre><code>ocid1.compartment.oc1..aaaaaaaapmqwjhsyggcyrvqxytrpgsfsqsvsrnnrmpnxmhjukpykajvnjdjj\n</code></pre>"},{"location":"devguide/ci/configuration/#virtual-cloud-network-vcn","title":"Virtual CLoud Network (VCN)","text":"<p>The VCN will have all the network related infrastructure used by this application. It will be needed to configure a router table with an Internet Gateway attached, a subnet and a security List.</p>"},{"location":"devguide/ci/configuration/#security-list","title":"Security List","text":"<p>The SECURITY_LIST_RULES configuration allows us to configure the opened ports for the instance. We just need HTTP/HTTPS and the provided SSH port.</p> <pre><code>SECURITY_LIST_RULES = [\n{\n    \"port\": 80,\n    \"description\": \"HTTP traffic for discord and monitoring connection to the bot\"\n},\n{\n    \"port\": 443,\n    \"description\": \"HTTPs traffic for discord and monitoring connection to the bot\"\n}\n</code></pre> <p>]</p>"},{"location":"devguide/ci/configuration/#instance","title":"Instance","text":"<p>The following configuration applies to the instance, the operating system and version will determine the image ocid used to  create the instance.</p> <pre><code>INSTANCE_OPERATING_SYSTEM = \"Canonical Ubuntu\"\nINSTANCE_OPERATING_SYSTEM_VERSION = \"20.04\"\nINSTANCE_SHAPE = \"VM.Standard.E2.1.Micro\"\n</code></pre>"},{"location":"devguide/ci/configuration/#image-identifier","title":"Image identifier","text":"<p>The identifier of the image depends on the image, build and region.</p> <p>The full list of OCIDs for images are listed here It's needed to enter on the Read more section to see the OCIDs for each region</p> <p></p> <p>To get it, the most recent not aarch64 image is selected matching the operating system and version configured for the actual region.</p>"},{"location":"devguide/ci/configuration/#instance-shape","title":"Instance shape","text":"<p>This is the shape of the compute instance created. It's a template that will determine the number of CPUs, amount of memory and other resources allocated.</p> <p>While creating an instance on the web console, it's the name displayed for the selected shape, for example:</p> <pre><code>VM.Standard.E2.1.Micro\n</code></pre> <p></p>"},{"location":"devguide/ci/jobs/","title":"Jobs","text":"<p>The pipeline execute multiple jobs in parallel. When every Job is finished, the deploy proceeds.</p>"},{"location":"devguide/ci/jobs/#check","title":"Check","text":"<p>Executes the gradle check task. It will run the unit tests and the integration tests. This task generates some jacoco reports that will be uploaded to codecov to show the current coverage of the project</p>"},{"location":"devguide/ci/jobs/#builddocs","title":"BuildDocs","text":"<p>This Job will build the docs under the docs folder. This folder contains a Docusaurus project that generates a static site by documentation written in markdown. The generated static site will be uploaded to the docs branch in the git repository.</p> <p>This branch will trigger a deployment of the site in the github pages under this url</p>"},{"location":"devguide/ci/jobs/#snyk","title":"Snyk","text":"<p>Executes an Snyk analysis to generate a vulnerability report.  It will upload the report to the official snyk site.</p> <p></p> <p>Snyk will show which dependencies included a vulnerability and a version which solve them, if exists.</p>"},{"location":"devguide/ci/jobs/#setupcaddy","title":"SetUpCaddy","text":"<p>This job will prepare the modified version of caddy we are using and upload it to the dockerhub. This image contains the corresponding header validator using the configured file.</p>"},{"location":"devguide/ci/jobs/#prepareimage","title":"PrepareImage","text":"<p>This Job will produce the necessary artifacts and images to pull and run the updated images. The main steps are:</p> <ul> <li>Run the bootJar gradle task to create the jar</li> <li>Publish the following artifacts:</li> <li>Caddyfile with the reverse-proxy configuration to route to the spring boot app</li> <li>Docker-compose file to run the needed docker-images</li> <li>The Jar with the latest spring boot app version.</li> <li>Build docker image with the corresponding jar</li> <li>Publish the docker image to the Docker Hub</li> </ul>"},{"location":"devguide/ci/jobs/#prepareoraclecloud","title":"PrepareOracleCLoud","text":"<p>This Job will create all the necessary resources to deploy the application in the Oracle Cloud.  It will use the python scripts on the pipeline folder of the project.</p> <p>If the resources already exists, it will reuse them.</p> <p>The output of this Job is the IP Address, so it will connect to the instance by ssh using that IP in the following Jobs,  instead of using anything related to the oracle console.</p> <p>Summary of tasks:  * Create infrastructure resources if they don't exist (nets and subnets, firewall rules, machines, compartment...)   * Obtain machine IP  * Install all necessary dependencies on a new created instances (like docker)</p>"},{"location":"devguide/ci/jobs/#deploy","title":"Deploy","text":"<p>The deployment will need all the other Jobs to be done before proceeding. It will download the artifacts generated in  the PrepareImage Job and push them to the deployment machine. It will pull the docker images and will restart the containers with the new version.</p> <p>This will generate a little downtime where the spring boot application will be starting </p>"},{"location":"devguide/ci/secrets/","title":"Secrets","text":"<p>Multiple secrets are used in the project. Most of them used during CI processes. But some other for the application.</p> <p>The secrets are managed by Github Secrets.</p>"},{"location":"devguide/ci/secrets/#external-tools-tokens","title":"External tools tokens","text":""},{"location":"devguide/ci/secrets/#dockerhub_token","title":"DOCKERHUB_TOKEN","text":"<p>Token used to upload to the docker hub the produced artifacts. </p> <ul> <li>The docker image with the jar application </li> <li>The custom caddy build</li> </ul> <p>It looks like an uuid</p> <pre><code>97963003-29b6-4484-9dae-6a9c7beda9df\n</code></pre> <p>Another token can be generated at the dockerhub settings</p> <p></p>"},{"location":"devguide/ci/secrets/#duckdns_token","title":"DUCKDNS_TOKEN","text":"<p>The token is used to link the current machine IP to the Duckdns domain.  Useful to automate the recreation of the instance.  It's used on the PrepareOracleCLoud job after the ip is obtained</p> <p>It looks like an uuid</p> <pre><code>97963003-29b6-4484-9dae-6a9c7beda9df\n</code></pre> <p>The token is one per user at the duckdns site. The domain is linked to this same GitHub account</p> <p></p>"},{"location":"devguide/ci/secrets/#snyk_token","title":"SNYK_TOKEN","text":"<p>This token serves to realise the analisis by the Snyk Job. The report is uploaded to the snyk site</p> <p>As stated in the documentation, Gradle Kotlin DSL files are not supported by the Github integration That's the reason the integration is made by the Snyk CLI in Github actions, which requires the token.</p> <p></p>"},{"location":"devguide/ci/secrets/#github_token","title":"GITHUB_TOKEN","text":"<p>This token is generated by Github so the workflow has access to publish in branches.</p> <p>It's used to publish the documentation in the docs branch.</p> <p>No need to generate a personal access token manually.</p>"},{"location":"devguide/ci/secrets/#oracle-cloud-secrets","title":"Oracle Cloud secrets","text":"<p>To connect to the Oracle cloud service some secrets and infrastructure details must be configured.</p> <p>Most of the information here can be found at in the official documentation as the original source of true.</p>"},{"location":"devguide/ci/secrets/#infra_fingerprint-and-infra_key_content","title":"INFRA_FINGERPRINT and INFRA_KEY_CONTENT","text":"<p>To access the console it's needed to create a RSA pair of public/private in PEM format. It can be generated with your  tool of choice or directly by the oracle cloud web interface.</p> <p>You can access and create them or upload the public key at the Oracle Cloud Web Console &gt; Profile &gt; User settings &gt; API Keys.</p> <p></p> <p>The fingerprint of the public key will be used as a parameter to create the session in the Oracle CLI.</p> <p>Adding a new API Key this way will provide the configuration file with some of the values required and explained below.</p> <p></p>"},{"location":"devguide/ci/secrets/#infra_region","title":"INFRA_REGION","text":"<p>Region of the Oracle cloud to be deployed into. The region is linked to the account the moment of registration.</p> <p>List of regions can be found at the official site</p>"},{"location":"devguide/ci/secrets/#infra_tenancy","title":"INFRA_TENANCY","text":"<p>Identifier of the tenancy for this account. The tenancy is the partition in the Oracle cloud where the account can create resources. It's created on sing up.</p> <p>The tenancy OCID can be found in the AWS console: Profile &gt; Tenancy</p> <p></p> <p></p> <p>And it will look something like this:</p> <pre><code>ocid1.tenancy.oc1..aaaaaaaapmqwjhsyggcyrvqxytrpgsfsqsvsrnnrmpnxmhjukpykajvnjdjj\n</code></pre>"},{"location":"devguide/ci/secrets/#infra_user_ocid","title":"INFRA_USER_OCID","text":"<p>User identifier accessing through the oracle cloud command line interface. In the web console, the OCID can be obtained in the user settings.</p> <p>Although the recommended way would be creating a user specific for integrations, I'm using my personal user for simplicity.</p> <p></p> <p>And it will look something like this:</p> <pre><code>ocid1.user.oc1.aaaaaaaapmqwjhsyggcyrvqxytrpgsfsqsvsrnnrmpnxmhjukpykajvnjdjj\n</code></pre>"},{"location":"devguide/ci/secrets/#s3-secrets","title":"S3 Secrets","text":"<p>Some secrets are needed to create an S3-compatible bucket in the oracle cloud. Details of this implementation can be  found at the persistence section</p>"},{"location":"devguide/ci/secrets/#s3_bucket_name","title":"S3_BUCKET_NAME","text":"<p>This is the name of the bucket created in the oracle cloud</p>"},{"location":"devguide/ci/secrets/#s3_access_key_id-s3_access_secret","title":"S3_ACCESS_KEY_ID &amp; S3_ACCESS_SECRET","text":"<p>This pair is generated through the user settings in the oracle cloud. Is used as a user/password to access the S3 bucket  from the container.</p> <p>To create it, go to the oracle cloud &gt; User Settings &gt; Customer secret keys &gt; Generate Secret Key</p> <p></p>"},{"location":"devguide/ci/secrets/#s3_url","title":"S3_URL","text":"<p>This is the url of the bucket in where the dump will be stored. It follows the structure of an oracle cloud bucket with a compatible S3 api, so it looks like:</p> <pre><code>https://&lt;namespace&gt;.compat.objectstorage.&lt;region&gt;.oraclecloud.com/\n</code></pre> <p>Cloud Object Storage URI Formats Understanding Object Storage Namespaces</p>"},{"location":"devguide/ci/secrets/#newrelic_key","title":"NEWRELIC_KEY","text":"<p>Secret key of the new relic agent for java applications. Originally located in the file newrelic.yml Obtained in the new relic cloud page to send application metrics and logs to be monitored.</p> <p></p> <p>Monitoring a java application in docker with New Relic</p>"},{"location":"devguide/ci/secrets/#vm-infrastructure-settings","title":"VM Infrastructure settings","text":"<p>The following secrets will be related to the deployment and the infrastructure where the application is deployed.  It's not related to the console configuration like the previous ones.</p>"},{"location":"devguide/ci/secrets/#infra_authorized_keys-infra_ssh_private_key","title":"INFRA_AUTHORIZED_KEYS, INFRA_SSH_PRIVATE_KEY","text":"<p>This is the authorized keys, private key pair to allow connections to the instance deployed.</p> <p>It's important not to confuse it with the OCI_KEY_FILE, since that's the CLI key  to access the console and this one is the authorized keys used for the machine being deployed. </p> <p>The authorized keys is needed to create the instance, while the private key is used in the Deploy step to connect to  the instance and deploy it.</p>"},{"location":"devguide/ci/secrets/#infra_availability_domain","title":"INFRA_AVAILABILITY_DOMAIN","text":"<p>The Availability Domain in which the instance will reside. </p> <p>The Availability domain is randomized by tenancy and data center. So to list the list of availability domains the  console or the SDK must be used, for example: </p> <pre><code>datocal@cloudshell:~ (&lt;region&gt;)$ oci iam availability-domain list\n{\n    \"data\": [\n        {\n            \"compartment-id\": &lt;compartment-ocid&gt;,\n            \"id\": &lt;availability-domain-ocid&gt;,\n            \"name\": &lt;availability-domain-name&gt;\n        },\n        {\n            \"compartment-id\": &lt;compartment-ocid&gt;,\n            \"id\": &lt;availability-domain-ocid&gt;,\n            \"name\": &lt;availability-domain-name&gt;\n        },\n        {\n            \"compartment-id\": &lt;compartment-ocid&gt;,\n            \"id\": &lt;availability-domain-ocid&gt;,\n            \"name\": &lt;availability-domain-name&gt;\n        }\n    ]\n}\n</code></pre> <p>This secret will be the name of the availability domain, for example:</p> <pre><code>UOCM:PHX-AD-1\n</code></pre> <p>In the Free Tier, the availability domain is restricted to a specific one.</p> <p>More information about this can be found  in the official documentation.</p>"},{"location":"userguide/","title":"List of available commands","text":"<p>For now there are only two silly commands. The commands are fully integrated with discord via  the Discord Interactions API</p>"},{"location":"userguide/#slash-commands","title":"Slash commands","text":"<p>Official reference guide to slash commands</p>"},{"location":"userguide/#the-culo-command","title":"The culo command","text":"<p>Invocation:</p> <pre><code>/culo\n</code></pre> <p>Response:</p> <pre><code>El culo tuyo\n</code></pre>"},{"location":"userguide/#message-commands","title":"Message commands","text":"<p>Official reference guide to message commands</p>"},{"location":"userguide/#the-roulette-command","title":"The roulette command","text":"<p>Invocation:</p> <p>Select a message with a line-by-line list of elements.  Click on the three dots &gt; Applications &gt; roulette.</p> <p>Response:</p> <p>A random line will be chosen from the message. ~~Striked lines~~ will not be processed</p> <p>Example image with request/response: </p>"}]}