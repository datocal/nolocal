{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NoLocal What This is a work in progress bot for discord servers. In the time writing this, the bot is only capable of two silly commands. But it has a great infrastructure to create and deploy a bot in few steps! you can see de details in the full documentation. The intention of this project is to create a layer of abstraction between multiple cloud providers to create game servers like minecraft by discord commands. Why There are lots of users that don't know how to create game servers, and the ones who knows how it works will have to go through a complex process to create instances, open them to public, open ports and more. With this solution, once it's configured on your favourite server, you can create instances and start/stop it as you use it, paying the server the time is being used. How The users of this bot will have to configure their clouds accounts through the bot. The bot will create, start and stop instances based on the commands. You can check out the full documentation in this site: >Documentation<","title":"Home"},{"location":"#nolocal","text":"","title":"NoLocal"},{"location":"#what","text":"This is a work in progress bot for discord servers. In the time writing this, the bot is only capable of two silly commands. But it has a great infrastructure to create and deploy a bot in few steps! you can see de details in the full documentation. The intention of this project is to create a layer of abstraction between multiple cloud providers to create game servers like minecraft by discord commands.","title":"What"},{"location":"#why","text":"There are lots of users that don't know how to create game servers, and the ones who knows how it works will have to go through a complex process to create instances, open them to public, open ports and more. With this solution, once it's configured on your favourite server, you can create instances and start/stop it as you use it, paying the server the time is being used.","title":"Why"},{"location":"#how","text":"The users of this bot will have to configure their clouds accounts through the bot. The bot will create, start and stop instances based on the commands. You can check out the full documentation in this site: >Documentation<","title":"How"},{"location":"devguide/","text":"Quickstart The Big Picture Tech stack Technology Type Description Reference Kotlin Language Modern JVM based language with full java compatibility Link Spring Boot Framework Robust and known framework to make the magic happens :) Link Gradle Build Tool Tool to build the project, with all the tasks related to compile, test and more Link Github Actions CI/CD Tool to orchestrate the checks, deploy and everything happening after a commit Link Sonarcloud Quality Analysis Tool to analyse the project to detect quality improvements (code smells, bugs...) Link Codecov Coverage Analysis Tool to show the testing coverage and its evolution Link MkDocs Static site generator Tool to generate a static site for documentation Link Oracle Cloud Hosting Cloud provider of this service deployment (free tier) Link Uptime Robot Monitoring Monitor to check the health of the application periodically by external http calls Link Building it To build the executable jar, just run: ./gradlew build This command will generate the jar output under build/libs Running it Just do: ./gradlew bootRun Or even simplier java -jar nolocal.jar Testing it All the tests are under the check task in gradle, so to run all the suite run: ./gradlew check Integration testing Integration tests are mixed with the unit tests, but on the infrastructure package. Originally, there was a split creating a separate module for the integration tests, but maintaining the gradle file was more difficult than the actual benefits of having it separated. Mutation testing You can run the mutation testing too! to do that, simply run ./gradlew pitest This will generate a report under build/reports/pitest/ In addition to this, the project has a job to generate the pitest report from GitHub","title":"Quickstart"},{"location":"devguide/#quickstart","text":"","title":"Quickstart"},{"location":"devguide/#the-big-picture","text":"","title":"The Big Picture"},{"location":"devguide/#tech-stack","text":"Technology Type Description Reference Kotlin Language Modern JVM based language with full java compatibility Link Spring Boot Framework Robust and known framework to make the magic happens :) Link Gradle Build Tool Tool to build the project, with all the tasks related to compile, test and more Link Github Actions CI/CD Tool to orchestrate the checks, deploy and everything happening after a commit Link Sonarcloud Quality Analysis Tool to analyse the project to detect quality improvements (code smells, bugs...) Link Codecov Coverage Analysis Tool to show the testing coverage and its evolution Link MkDocs Static site generator Tool to generate a static site for documentation Link Oracle Cloud Hosting Cloud provider of this service deployment (free tier) Link Uptime Robot Monitoring Monitor to check the health of the application periodically by external http calls Link","title":"Tech stack"},{"location":"devguide/#building-it","text":"To build the executable jar, just run: ./gradlew build This command will generate the jar output under build/libs","title":"Building it"},{"location":"devguide/#running-it","text":"Just do: ./gradlew bootRun Or even simplier java -jar nolocal.jar","title":"Running it"},{"location":"devguide/#testing-it","text":"All the tests are under the check task in gradle, so to run all the suite run: ./gradlew check","title":"Testing it"},{"location":"devguide/#integration-testing","text":"Integration tests are mixed with the unit tests, but on the infrastructure package. Originally, there was a split creating a separate module for the integration tests, but maintaining the gradle file was more difficult than the actual benefits of having it separated.","title":"Integration testing"},{"location":"devguide/#mutation-testing","text":"You can run the mutation testing too! to do that, simply run ./gradlew pitest This will generate a report under build/reports/pitest/ In addition to this, the project has a job to generate the pitest report from GitHub","title":"Mutation testing"},{"location":"devguide/addingCommands/","text":"Adding commands Registering commands To make a command available in the server it's needed to register it in the discord API. It can be registered as a global or a specific server command. This process is not automated, as the time of writing this, the process is as simple as to make a POST request with the command specification. You can check the specific documentation in the following link Programming slash commands Adding commands is pretty straightforward. You just have to create a Spring bean. The name of the bean must be the command to listen. This bean has to implement the following interface: com.datocal.nolocal.infrastructure.commands.DiscordCommand For example, this would be a ping command: @Component(\"ping\") class PingCommand(private val ping: Ping) : DiscordCommand { override fun accept(interaction: Interaction): InteractionResponse { return InteractionResponse(ping.ping()) } } And, for the discord registration to work, it must be documented with the @Command annotation. Description cannot be informed for message commands. @Command( command = \"ping\", description = \"Just a ping command\", type = Command.TYPE_CHAT_INPUT, ) The notation @Component(\"ping\") will create the infrastructure necessary to create the bean and call this Runner when the ping command is invoked. You just have to implement the method returning an InteractionResponse. The notation @Command will add the command to discord at startup if it's not already in the discord configuration. How the magic works The annotation @Component is a spring annotation. For those not familiarized with spring, this will initialize this class calling its constructor and put it in a magic box to take it any time it's needed in a program. In the shadows, Spring will create a Map with all the beans of type DiscordCommand in the application, using the bean name (the command string in this case) as the key. We will use this to map any command received to this bean. To use the map, there is a controller who listens for upcoming commands, the interactions endpoint @RestController class InteractionsController( private val commands: Map<String, DiscordCommand> ) { @PostMapping(\"/discord/interactions\") fun execute(@RequestBody interaction: Interaction): InteractionResponse { return commands[interaction.command]?.accept(interaction) ?: defaultResponse() } //ACK Discord PING checks private fun defaultResponse() = InteractionResponse() } Discord requires this endpoint to receive upcoming commands. In production, this endpoint is protected by a reverse proxy to only allow requests coming from discord. The proxy will require a header with the request encrypted with a private key owned by discord. This class is located at the following package: com.datocal.nolocal.infrastructure.discord.controller.InteractionsController The registration on commands via discord works by a bean with a @PostConstruct annotation that register the command via api, using the class in: com.datocal.nolocal.infrastructure.discord.CommandRegistrator","title":"Adding Commands"},{"location":"devguide/addingCommands/#adding-commands","text":"","title":"Adding commands"},{"location":"devguide/addingCommands/#registering-commands","text":"To make a command available in the server it's needed to register it in the discord API. It can be registered as a global or a specific server command. This process is not automated, as the time of writing this, the process is as simple as to make a POST request with the command specification. You can check the specific documentation in the following link","title":"Registering commands"},{"location":"devguide/addingCommands/#programming-slash-commands","text":"Adding commands is pretty straightforward. You just have to create a Spring bean. The name of the bean must be the command to listen. This bean has to implement the following interface: com.datocal.nolocal.infrastructure.commands.DiscordCommand For example, this would be a ping command: @Component(\"ping\") class PingCommand(private val ping: Ping) : DiscordCommand { override fun accept(interaction: Interaction): InteractionResponse { return InteractionResponse(ping.ping()) } } And, for the discord registration to work, it must be documented with the @Command annotation. Description cannot be informed for message commands. @Command( command = \"ping\", description = \"Just a ping command\", type = Command.TYPE_CHAT_INPUT, ) The notation @Component(\"ping\") will create the infrastructure necessary to create the bean and call this Runner when the ping command is invoked. You just have to implement the method returning an InteractionResponse. The notation @Command will add the command to discord at startup if it's not already in the discord configuration.","title":"Programming slash commands"},{"location":"devguide/addingCommands/#how-the-magic-works","text":"The annotation @Component is a spring annotation. For those not familiarized with spring, this will initialize this class calling its constructor and put it in a magic box to take it any time it's needed in a program. In the shadows, Spring will create a Map with all the beans of type DiscordCommand in the application, using the bean name (the command string in this case) as the key. We will use this to map any command received to this bean. To use the map, there is a controller who listens for upcoming commands, the interactions endpoint @RestController class InteractionsController( private val commands: Map<String, DiscordCommand> ) { @PostMapping(\"/discord/interactions\") fun execute(@RequestBody interaction: Interaction): InteractionResponse { return commands[interaction.command]?.accept(interaction) ?: defaultResponse() } //ACK Discord PING checks private fun defaultResponse() = InteractionResponse() } Discord requires this endpoint to receive upcoming commands. In production, this endpoint is protected by a reverse proxy to only allow requests coming from discord. The proxy will require a header with the request encrypted with a private key owned by discord. This class is located at the following package: com.datocal.nolocal.infrastructure.discord.controller.InteractionsController The registration on commands via discord works by a bean with a @PostConstruct annotation that register the command via api, using the class in: com.datocal.nolocal.infrastructure.discord.CommandRegistrator","title":"How the magic works"},{"location":"devguide/persistence/","text":"Persistence Persistence is done by a redis container. Redis has multiple strategies to write data to disk. The chosen one is the default persistence, Redis Database (RDB). By default it will save snapshots of the dataset each 60 seconds. It may seem weak, but it should not be an issue at all, worst case scenario would be a lost of 60 seconds of data and with few users it will be acceptable. However, having the redis dockerized inside a Virtual Machine forces to maintain a process to keep the data in another point to be able to destroy the machine and create another. That's where several technologies come into play: Redis : The official redis image from dockerhub . Oracle Object Storage : AWS S3 like bucket. Used to store the redis dumps. S3FS : Tool to mount S3 buckets into a file system. Docker volumes : A volume is created from a container using s3fs linking the host with the bucket. Another mount is made to link that host's folder to the redis container. Related info: * Overview of Object Storage : https://docs.oracle.com/en-us/iaas/Content/Object/Concepts/objectstorageoverview.htm * Mounting Object Storage buckets using s3fs : https://docs.oracle.com/en-us/iaas/Content/Object/Tasks/s3compatibleapi.htm#Supported_Amazon_S3_Clients * Official s3fs-fuse repository : https://github.com/s3fs-fuse/s3fs-fuse * Dockerized s3fs-fuse implementation : https://github.com/efrecon/docker-s3fs-client Compose explanation The following code is a valid configuration to use the bucket as a volume: s3fs: image: 'efrecon/s3fs:1.91' container_name: s3fs devices: - /dev/fuse cap_add: - SYS_ADMIN security_opt: - 'apparmor:unconfined' stop_signal: SIGINT volumes: - '/mnt/nolocal:/opt/s3fs/bucket:rshared' environment: - AWS_S3_BUCKET - AWS_S3_MOUNT - AWS_S3_ACCESS_KEY_ID - AWS_S3_SECRET_ACCESS_KEY - AWS_S3_URL - S3FS_ARGS - S3FS_DEBUG - UID - GID image : The image version generated automatically based on the s3fs implementation, so it will keep up to date. devices, cap_add & security_opt : Make sure the container will be able to make availablo the S3 bucket stop_signal : By default, this image is prepared to be launched by docker-run, so it waits for the Ctrl+C (SIGINT) signal. Docker compose automatically sends SIGTERM on docker termination (by for example, a docker-compose stop command) This way the signal is overwritten and the container handles the termination correctly. Failing to do so will leave the mount in an inconsistent state. volumes : The left one will be the host mount point while de right one the docker one. rshared makes the volume available to the host and other containers. environment : Some of them are explained on the secrets section . For the other ones: S3FS_ARGS : Two options are passed to S3FS: use_path_request_style: Mandatory to use S3-compatible implementations instead of an AWS S3 official bucket allow_other: Used to be able to access the mount outside the s3fs container. UID & GID : UID & GID of the redis user and group created in the redis container. This will make a chown and will let redis access to the mount.","title":"Persistence"},{"location":"devguide/persistence/#persistence","text":"Persistence is done by a redis container. Redis has multiple strategies to write data to disk. The chosen one is the default persistence, Redis Database (RDB). By default it will save snapshots of the dataset each 60 seconds. It may seem weak, but it should not be an issue at all, worst case scenario would be a lost of 60 seconds of data and with few users it will be acceptable. However, having the redis dockerized inside a Virtual Machine forces to maintain a process to keep the data in another point to be able to destroy the machine and create another. That's where several technologies come into play: Redis : The official redis image from dockerhub . Oracle Object Storage : AWS S3 like bucket. Used to store the redis dumps. S3FS : Tool to mount S3 buckets into a file system. Docker volumes : A volume is created from a container using s3fs linking the host with the bucket. Another mount is made to link that host's folder to the redis container. Related info: * Overview of Object Storage : https://docs.oracle.com/en-us/iaas/Content/Object/Concepts/objectstorageoverview.htm * Mounting Object Storage buckets using s3fs : https://docs.oracle.com/en-us/iaas/Content/Object/Tasks/s3compatibleapi.htm#Supported_Amazon_S3_Clients * Official s3fs-fuse repository : https://github.com/s3fs-fuse/s3fs-fuse * Dockerized s3fs-fuse implementation : https://github.com/efrecon/docker-s3fs-client","title":"Persistence"},{"location":"devguide/persistence/#compose-explanation","text":"The following code is a valid configuration to use the bucket as a volume: s3fs: image: 'efrecon/s3fs:1.91' container_name: s3fs devices: - /dev/fuse cap_add: - SYS_ADMIN security_opt: - 'apparmor:unconfined' stop_signal: SIGINT volumes: - '/mnt/nolocal:/opt/s3fs/bucket:rshared' environment: - AWS_S3_BUCKET - AWS_S3_MOUNT - AWS_S3_ACCESS_KEY_ID - AWS_S3_SECRET_ACCESS_KEY - AWS_S3_URL - S3FS_ARGS - S3FS_DEBUG - UID - GID image : The image version generated automatically based on the s3fs implementation, so it will keep up to date. devices, cap_add & security_opt : Make sure the container will be able to make availablo the S3 bucket stop_signal : By default, this image is prepared to be launched by docker-run, so it waits for the Ctrl+C (SIGINT) signal. Docker compose automatically sends SIGTERM on docker termination (by for example, a docker-compose stop command) This way the signal is overwritten and the container handles the termination correctly. Failing to do so will leave the mount in an inconsistent state. volumes : The left one will be the host mount point while de right one the docker one. rshared makes the volume available to the host and other containers. environment : Some of them are explained on the secrets section . For the other ones: S3FS_ARGS : Two options are passed to S3FS: use_path_request_style: Mandatory to use S3-compatible implementations instead of an AWS S3 official bucket allow_other: Used to be able to access the mount outside the s3fs container. UID & GID : UID & GID of the redis user and group created in the redis container. This will make a chown and will let redis access to the mount.","title":"Compose explanation"},{"location":"devguide/security/","text":"Security In order to be validated by discord, the implemented interactions endpoint must validate that the invocation is coming from discord. The full details about how discord send messages and how to validate them can be found in their official documentation To implement this, a caddy service is set up using the CarsonHoffman mod for caddy . The Caddy reverse proxy will check the calls to the interactions endpoint veryfing the headers to ensure the call is made from discord. The modified caddy has been built and uploaded to the docker hub","title":"Security"},{"location":"devguide/security/#security","text":"In order to be validated by discord, the implemented interactions endpoint must validate that the invocation is coming from discord. The full details about how discord send messages and how to validate them can be found in their official documentation To implement this, a caddy service is set up using the CarsonHoffman mod for caddy . The Caddy reverse proxy will check the calls to the interactions endpoint veryfing the headers to ensure the call is made from discord. The modified caddy has been built and uploaded to the docker hub","title":"Security"},{"location":"devguide/ci/","text":"Quick View This project contains a full pipeline from 0 to production using Github Actions. There is a bunch of pipelines configured but the important one is the pipeline-jobs pipeline. Generate Docs: This pipeline only generates the docs. But the main one generates them too when pushing to master, so it's useless Mutation Tests: This pipeline runs the mutation tests and generates a report showing the real coverage. CI: This is the main pipeline with parallel jobs, infrastructure creation and deploy to production. Termination: This pipeline terminates all the resources in the cloud. pages-build-deployment: Pipeline generated by the buildDocs step on the main pipeline to deploy the documentation on gh pages. The following image shows the current jobs for the main pipeline: Generated artifacts compose: The docker-compose file. Used in the deployment to launch the docker images documentation: The documentation site in a compressed zip file. artifact: The jar containing the NoLocal Spring Boot application.","title":"Quick View"},{"location":"devguide/ci/#quick-view","text":"This project contains a full pipeline from 0 to production using Github Actions. There is a bunch of pipelines configured but the important one is the pipeline-jobs pipeline. Generate Docs: This pipeline only generates the docs. But the main one generates them too when pushing to master, so it's useless Mutation Tests: This pipeline runs the mutation tests and generates a report showing the real coverage. CI: This is the main pipeline with parallel jobs, infrastructure creation and deploy to production. Termination: This pipeline terminates all the resources in the cloud. pages-build-deployment: Pipeline generated by the buildDocs step on the main pipeline to deploy the documentation on gh pages. The following image shows the current jobs for the main pipeline:","title":"Quick View"},{"location":"devguide/ci/#generated-artifacts","text":"compose: The docker-compose file. Used in the deployment to launch the docker images documentation: The documentation site in a compressed zip file. artifact: The jar containing the NoLocal Spring Boot application.","title":"Generated artifacts"},{"location":"devguide/ci/configuration/","text":"CI configuration All the non related infrastructure configuration is managed by the secrets explained in the previous section The following section contains the configuration needed on the python pipeline to create the infrastructure in the oracle cloud. The configuration is stored at the pipeline/config.py file. Compartment The compartment will be the root of all the resources created for this application. The organization in the cloud infrastructure is divided into compartments to organize resources. It's created / deleted based on its name in the COMPARTMENT_NAME variable. Creating a custom compartment allows to isolate the application resources from the rest of the cloud resources we may be using in the account. On creation/getting it from the existing ones by name, it will use an OCID like this: ocid1.compartment.oc1..aaaaaaaapmqwjhsyggcyrvqxytrpgsfsqsvsrnnrmpnxmhjukpykajvnjdjj Virtual CLoud Network (VCN) The VCN will have all the network related infrastructure used by this application. It will be needed to configure a router table with an Internet Gateway attached, a subnet and a security List. Security List The SECURITY_LIST_RULES configuration allows us to configure the opened ports for the instance. We just need HTTP/HTTPS and the provided SSH port. SECURITY_LIST_RULES = [ { \"port\": 80, \"description\": \"HTTP traffic for discord and monitoring connection to the bot\" }, { \"port\": 443, \"description\": \"HTTPs traffic for discord and monitoring connection to the bot\" } ] Instance The following configuration applies to the instance, the operating system and version will determine the image ocid used to create the instance. INSTANCE_OPERATING_SYSTEM = \"Canonical Ubuntu\" INSTANCE_OPERATING_SYSTEM_VERSION = \"20.04\" INSTANCE_SHAPE = \"VM.Standard.E2.1.Micro\" Image identifier The identifier of the image depends on the image, build and region. The full list of OCIDs for images are listed here It's needed to enter on the Read more section to see the OCIDs for each region To get it, the most recent not aarch64 image is selected matching the operating system and version configured for the actual region. Instance shape This is the shape of the compute instance created. It's a template that will determine the number of CPUs, amount of memory and other resources allocated. While creating an instance on the web console, it's the name displayed for the selected shape, for example: VM.Standard.E2.1.Micro","title":"Configuration"},{"location":"devguide/ci/configuration/#ci-configuration","text":"All the non related infrastructure configuration is managed by the secrets explained in the previous section The following section contains the configuration needed on the python pipeline to create the infrastructure in the oracle cloud. The configuration is stored at the pipeline/config.py file.","title":"CI configuration"},{"location":"devguide/ci/configuration/#compartment","text":"The compartment will be the root of all the resources created for this application. The organization in the cloud infrastructure is divided into compartments to organize resources. It's created / deleted based on its name in the COMPARTMENT_NAME variable. Creating a custom compartment allows to isolate the application resources from the rest of the cloud resources we may be using in the account. On creation/getting it from the existing ones by name, it will use an OCID like this: ocid1.compartment.oc1..aaaaaaaapmqwjhsyggcyrvqxytrpgsfsqsvsrnnrmpnxmhjukpykajvnjdjj","title":"Compartment"},{"location":"devguide/ci/configuration/#virtual-cloud-network-vcn","text":"The VCN will have all the network related infrastructure used by this application. It will be needed to configure a router table with an Internet Gateway attached, a subnet and a security List.","title":"Virtual CLoud Network (VCN)"},{"location":"devguide/ci/configuration/#security-list","text":"The SECURITY_LIST_RULES configuration allows us to configure the opened ports for the instance. We just need HTTP/HTTPS and the provided SSH port. SECURITY_LIST_RULES = [ { \"port\": 80, \"description\": \"HTTP traffic for discord and monitoring connection to the bot\" }, { \"port\": 443, \"description\": \"HTTPs traffic for discord and monitoring connection to the bot\" } ]","title":"Security List"},{"location":"devguide/ci/configuration/#instance","text":"The following configuration applies to the instance, the operating system and version will determine the image ocid used to create the instance. INSTANCE_OPERATING_SYSTEM = \"Canonical Ubuntu\" INSTANCE_OPERATING_SYSTEM_VERSION = \"20.04\" INSTANCE_SHAPE = \"VM.Standard.E2.1.Micro\"","title":"Instance"},{"location":"devguide/ci/configuration/#image-identifier","text":"The identifier of the image depends on the image, build and region. The full list of OCIDs for images are listed here It's needed to enter on the Read more section to see the OCIDs for each region To get it, the most recent not aarch64 image is selected matching the operating system and version configured for the actual region.","title":"Image identifier"},{"location":"devguide/ci/configuration/#instance-shape","text":"This is the shape of the compute instance created. It's a template that will determine the number of CPUs, amount of memory and other resources allocated. While creating an instance on the web console, it's the name displayed for the selected shape, for example: VM.Standard.E2.1.Micro","title":"Instance shape"},{"location":"devguide/ci/jobs/","text":"Jobs The pipeline execute multiple jobs in parallel. When every Job is finished, the deploy proceeds. Check Executes the gradle check task. It will run the unit tests and the integration tests. This task generates some jacoco reports that will be uploaded to codecov to show the current coverage of the project BuildDocs This Job will build the docs under the docs folder. This folder contains a Docusaurus project that generates a static site by documentation written in markdown. The generated static site will be uploaded to the docs branch in the git repository. This branch will trigger a deployment of the site in the github pages under this url Snyk Executes an Snyk analysis to generate a vulnerability report. It will upload the report to the official snyk site . Snyk will show which dependencies included a vulnerability and a version which solve them, if exists. SetUpCaddy This job will prepare the modified version of caddy we are using and upload it to the dockerhub . This image contains the corresponding header validator using the configured file . PrepareImage This Job will produce the necessary artifacts and images to pull and run the updated images. The main steps are: Run the bootJar gradle task to create the jar Publish the following artifacts: Caddyfile with the reverse-proxy configuration to route to the spring boot app Docker-compose file to run the needed docker-images The Jar with the latest spring boot app version. Build docker image with the corresponding jar Publish the docker image to the Docker Hub PrepareOracleCLoud This Job will create all the necessary resources to deploy the application in the Oracle Cloud. It will use the python scripts on the pipeline folder of the project. If the resources already exists, it will reuse them. The output of this Job is the IP Address, so it will connect to the instance by ssh using that IP in the following Jobs, instead of using anything related to the oracle console. Summary of tasks: * Create infrastructure resources if they don't exist (nets and subnets, firewall rules, machines, compartment...) * Obtain machine IP * Install all necessary dependencies on a new created instances (like docker) Deploy The deployment will need all the other Jobs to be done before proceeding. It will download the artifacts generated in the PrepareImage Job and push them to the deployment machine. It will pull the docker images and will restart the containers with the new version. This will generate a little downtime where the spring boot application will be starting","title":"Jobs"},{"location":"devguide/ci/jobs/#jobs","text":"The pipeline execute multiple jobs in parallel. When every Job is finished, the deploy proceeds.","title":"Jobs"},{"location":"devguide/ci/jobs/#check","text":"Executes the gradle check task. It will run the unit tests and the integration tests. This task generates some jacoco reports that will be uploaded to codecov to show the current coverage of the project","title":"Check"},{"location":"devguide/ci/jobs/#builddocs","text":"This Job will build the docs under the docs folder. This folder contains a Docusaurus project that generates a static site by documentation written in markdown. The generated static site will be uploaded to the docs branch in the git repository. This branch will trigger a deployment of the site in the github pages under this url","title":"BuildDocs"},{"location":"devguide/ci/jobs/#snyk","text":"Executes an Snyk analysis to generate a vulnerability report. It will upload the report to the official snyk site . Snyk will show which dependencies included a vulnerability and a version which solve them, if exists.","title":"Snyk"},{"location":"devguide/ci/jobs/#setupcaddy","text":"This job will prepare the modified version of caddy we are using and upload it to the dockerhub . This image contains the corresponding header validator using the configured file .","title":"SetUpCaddy"},{"location":"devguide/ci/jobs/#prepareimage","text":"This Job will produce the necessary artifacts and images to pull and run the updated images. The main steps are: Run the bootJar gradle task to create the jar Publish the following artifacts: Caddyfile with the reverse-proxy configuration to route to the spring boot app Docker-compose file to run the needed docker-images The Jar with the latest spring boot app version. Build docker image with the corresponding jar Publish the docker image to the Docker Hub","title":"PrepareImage"},{"location":"devguide/ci/jobs/#prepareoraclecloud","text":"This Job will create all the necessary resources to deploy the application in the Oracle Cloud. It will use the python scripts on the pipeline folder of the project. If the resources already exists, it will reuse them. The output of this Job is the IP Address, so it will connect to the instance by ssh using that IP in the following Jobs, instead of using anything related to the oracle console. Summary of tasks: * Create infrastructure resources if they don't exist (nets and subnets, firewall rules, machines, compartment...) * Obtain machine IP * Install all necessary dependencies on a new created instances (like docker)","title":"PrepareOracleCLoud"},{"location":"devguide/ci/jobs/#deploy","text":"The deployment will need all the other Jobs to be done before proceeding. It will download the artifacts generated in the PrepareImage Job and push them to the deployment machine. It will pull the docker images and will restart the containers with the new version. This will generate a little downtime where the spring boot application will be starting","title":"Deploy"},{"location":"devguide/ci/secrets/","text":"Secrets Multiple secrets are used in the project. Most of them used during CI processes. But some other for the application. The secrets are managed by Github Secrets. External tools tokens DOCKERHUB_TOKEN Token used to upload to the docker hub the produced artifacts. The docker image with the jar application The custom caddy build It looks like an uuid 97963003-29b6-4484-9dae-6a9c7beda9df Another token can be generated at the dockerhub settings DUCKDNS_TOKEN The token is used to link the current machine IP to the Duckdns domain. Useful to automate the recreation of the instance. It's used on the PrepareOracleCLoud job after the ip is obtained It looks like an uuid 97963003-29b6-4484-9dae-6a9c7beda9df The token is one per user at the duckdns site. The domain is linked to this same GitHub account SNYK_TOKEN This token serves to realise the analisis by the Snyk Job . The report is uploaded to the snyk site As stated in the documentation, Gradle Kotlin DSL files are not supported by the Github integration That's the reason the integration is made by the Snyk CLI in Github actions, which requires the token. GITHUB_TOKEN This token is generated by Github so the workflow has access to publish in branches. It's used to publish the documentation in the docs branch. No need to generate a personal access token manually. Oracle Cloud secrets To connect to the Oracle cloud service some secrets and infrastructure details must be configured. Most of the information here can be found at in the official documentation as the original source of true. INFRA_FINGERPRINT and INFRA_KEY_CONTENT To access the console it's needed to create a RSA pair of public/private in PEM format. It can be generated with your tool of choice or directly by the oracle cloud web interface. You can access and create them or upload the public key at the Oracle Cloud Web Console > Profile > User settings > API Keys. The fingerprint of the public key will be used as a parameter to create the session in the Oracle CLI. Adding a new API Key this way will provide the configuration file with some of the values required and explained below. INFRA_REGION Region of the Oracle cloud to be deployed into. The region is linked to the account the moment of registration. List of regions can be found at the official site INFRA_TENANCY Identifier of the tenancy for this account. The tenancy is the partition in the Oracle cloud where the account can create resources. It's created on sing up. The tenancy OCID can be found in the AWS console: Profile > Tenancy And it will look something like this: ocid1.tenancy.oc1..aaaaaaaapmqwjhsyggcyrvqxytrpgsfsqsvsrnnrmpnxmhjukpykajvnjdjj INFRA_USER_OCID User identifier accessing through the oracle cloud command line interface. In the web console, the OCID can be obtained in the user settings. Although the recommended way would be creating a user specific for integrations, I'm using my personal user for simplicity. And it will look something like this: ocid1.user.oc1.aaaaaaaapmqwjhsyggcyrvqxytrpgsfsqsvsrnnrmpnxmhjukpykajvnjdjj S3 Secrets Some secrets are needed to create an S3-compatible bucket in the oracle cloud. Details of this implementation can be found at the persistence section S3_BUCKET_NAME This is the name of the bucket created in the oracle cloud S3_ACCESS_KEY_ID & S3_ACCESS_SECRET This pair is generated through the user settings in the oracle cloud. Is used as a user/password to access the S3 bucket from the container. To create it, go to the oracle cloud > User Settings > Customer secret keys > Generate Secret Key S3_URL This is the url of the bucket in where the dump will be stored. It follows the structure of an oracle cloud bucket with a compatible S3 api, so it looks like: https://<namespace>.compat.objectstorage.<region>.oraclecloud.com/ Cloud Object Storage URI Formats Understanding Object Storage Namespaces VM Infrastructure settings The following secrets will be related to the deployment and the infrastructure where the application is deployed. It's not related to the console configuration like the previous ones. INFRA_AUTHORIZED_KEYS, INFRA_SSH_PRIVATE_KEY This is the authorized keys, private key pair to allow connections to the instance deployed. It's important not to confuse it with the OCI_KEY_FILE , since that's the CLI key to access the console and this one is the authorized keys used for the machine being deployed. The authorized keys is needed to create the instance, while the private key is used in the Deploy step to connect to the instance and deploy it. INFRA_AVAILABILITY_DOMAIN The Availability Domain in which the instance will reside. The Availability domain is randomized by tenancy and data center. So to list the list of availability domains the console or the SDK must be used, for example: datocal@cloudshell:~ (<region>)$ oci iam availability-domain list { \"data\": [ { \"compartment-id\": <compartment-ocid>, \"id\": <availability-domain-ocid>, \"name\": <availability-domain-name> }, { \"compartment-id\": <compartment-ocid>, \"id\": <availability-domain-ocid>, \"name\": <availability-domain-name> }, { \"compartment-id\": <compartment-ocid>, \"id\": <availability-domain-ocid>, \"name\": <availability-domain-name> } ] } This secret will be the name of the availability domain, for example: UOCM:PHX-AD-1 In the Free Tier, the availability domain is restricted to a specific one. More information about this can be found in the official documentation.","title":"Secrets"},{"location":"devguide/ci/secrets/#secrets","text":"Multiple secrets are used in the project. Most of them used during CI processes. But some other for the application. The secrets are managed by Github Secrets.","title":"Secrets"},{"location":"devguide/ci/secrets/#external-tools-tokens","text":"","title":"External tools tokens"},{"location":"devguide/ci/secrets/#dockerhub_token","text":"Token used to upload to the docker hub the produced artifacts. The docker image with the jar application The custom caddy build It looks like an uuid 97963003-29b6-4484-9dae-6a9c7beda9df Another token can be generated at the dockerhub settings","title":"DOCKERHUB_TOKEN"},{"location":"devguide/ci/secrets/#duckdns_token","text":"The token is used to link the current machine IP to the Duckdns domain. Useful to automate the recreation of the instance. It's used on the PrepareOracleCLoud job after the ip is obtained It looks like an uuid 97963003-29b6-4484-9dae-6a9c7beda9df The token is one per user at the duckdns site. The domain is linked to this same GitHub account","title":"DUCKDNS_TOKEN"},{"location":"devguide/ci/secrets/#snyk_token","text":"This token serves to realise the analisis by the Snyk Job . The report is uploaded to the snyk site As stated in the documentation, Gradle Kotlin DSL files are not supported by the Github integration That's the reason the integration is made by the Snyk CLI in Github actions, which requires the token.","title":"SNYK_TOKEN"},{"location":"devguide/ci/secrets/#github_token","text":"This token is generated by Github so the workflow has access to publish in branches. It's used to publish the documentation in the docs branch. No need to generate a personal access token manually.","title":"GITHUB_TOKEN"},{"location":"devguide/ci/secrets/#oracle-cloud-secrets","text":"To connect to the Oracle cloud service some secrets and infrastructure details must be configured. Most of the information here can be found at in the official documentation as the original source of true.","title":"Oracle Cloud secrets"},{"location":"devguide/ci/secrets/#infra_fingerprint-and-infra_key_content","text":"To access the console it's needed to create a RSA pair of public/private in PEM format. It can be generated with your tool of choice or directly by the oracle cloud web interface. You can access and create them or upload the public key at the Oracle Cloud Web Console > Profile > User settings > API Keys. The fingerprint of the public key will be used as a parameter to create the session in the Oracle CLI. Adding a new API Key this way will provide the configuration file with some of the values required and explained below.","title":"INFRA_FINGERPRINT and INFRA_KEY_CONTENT"},{"location":"devguide/ci/secrets/#infra_region","text":"Region of the Oracle cloud to be deployed into. The region is linked to the account the moment of registration. List of regions can be found at the official site","title":"INFRA_REGION"},{"location":"devguide/ci/secrets/#infra_tenancy","text":"Identifier of the tenancy for this account. The tenancy is the partition in the Oracle cloud where the account can create resources. It's created on sing up. The tenancy OCID can be found in the AWS console: Profile > Tenancy And it will look something like this: ocid1.tenancy.oc1..aaaaaaaapmqwjhsyggcyrvqxytrpgsfsqsvsrnnrmpnxmhjukpykajvnjdjj","title":"INFRA_TENANCY"},{"location":"devguide/ci/secrets/#infra_user_ocid","text":"User identifier accessing through the oracle cloud command line interface. In the web console, the OCID can be obtained in the user settings. Although the recommended way would be creating a user specific for integrations, I'm using my personal user for simplicity. And it will look something like this: ocid1.user.oc1.aaaaaaaapmqwjhsyggcyrvqxytrpgsfsqsvsrnnrmpnxmhjukpykajvnjdjj","title":"INFRA_USER_OCID"},{"location":"devguide/ci/secrets/#s3-secrets","text":"Some secrets are needed to create an S3-compatible bucket in the oracle cloud. Details of this implementation can be found at the persistence section","title":"S3 Secrets"},{"location":"devguide/ci/secrets/#s3_bucket_name","text":"This is the name of the bucket created in the oracle cloud","title":"S3_BUCKET_NAME"},{"location":"devguide/ci/secrets/#s3_access_key_id-s3_access_secret","text":"This pair is generated through the user settings in the oracle cloud. Is used as a user/password to access the S3 bucket from the container. To create it, go to the oracle cloud > User Settings > Customer secret keys > Generate Secret Key","title":"S3_ACCESS_KEY_ID &amp; S3_ACCESS_SECRET"},{"location":"devguide/ci/secrets/#s3_url","text":"This is the url of the bucket in where the dump will be stored. It follows the structure of an oracle cloud bucket with a compatible S3 api, so it looks like: https://<namespace>.compat.objectstorage.<region>.oraclecloud.com/ Cloud Object Storage URI Formats Understanding Object Storage Namespaces","title":"S3_URL"},{"location":"devguide/ci/secrets/#vm-infrastructure-settings","text":"The following secrets will be related to the deployment and the infrastructure where the application is deployed. It's not related to the console configuration like the previous ones.","title":"VM Infrastructure settings"},{"location":"devguide/ci/secrets/#infra_authorized_keys-infra_ssh_private_key","text":"This is the authorized keys, private key pair to allow connections to the instance deployed. It's important not to confuse it with the OCI_KEY_FILE , since that's the CLI key to access the console and this one is the authorized keys used for the machine being deployed. The authorized keys is needed to create the instance, while the private key is used in the Deploy step to connect to the instance and deploy it.","title":"INFRA_AUTHORIZED_KEYS, INFRA_SSH_PRIVATE_KEY"},{"location":"devguide/ci/secrets/#infra_availability_domain","text":"The Availability Domain in which the instance will reside. The Availability domain is randomized by tenancy and data center. So to list the list of availability domains the console or the SDK must be used, for example: datocal@cloudshell:~ (<region>)$ oci iam availability-domain list { \"data\": [ { \"compartment-id\": <compartment-ocid>, \"id\": <availability-domain-ocid>, \"name\": <availability-domain-name> }, { \"compartment-id\": <compartment-ocid>, \"id\": <availability-domain-ocid>, \"name\": <availability-domain-name> }, { \"compartment-id\": <compartment-ocid>, \"id\": <availability-domain-ocid>, \"name\": <availability-domain-name> } ] } This secret will be the name of the availability domain, for example: UOCM:PHX-AD-1 In the Free Tier, the availability domain is restricted to a specific one. More information about this can be found in the official documentation.","title":"INFRA_AVAILABILITY_DOMAIN"},{"location":"userguide/","text":"List of available commands For now there are only two silly commands. The commands are fully integrated with discord via the Discord Interactions API Slash commands Official reference guide to slash commands The culo command Invocation: /culo Response: El culo tuyo Message commands Official reference guide to message commands The roulette command Invocation: Select a message with a line-by-line list of elements. Click on the three dots > Applications > roulette. Response: A random line will be chosen from the message. ~~Striked lines~~ will not be processed Example image with request/response:","title":"User Guide"},{"location":"userguide/#list-of-available-commands","text":"For now there are only two silly commands. The commands are fully integrated with discord via the Discord Interactions API","title":"List of available commands"},{"location":"userguide/#slash-commands","text":"Official reference guide to slash commands","title":"Slash commands"},{"location":"userguide/#the-culo-command","text":"Invocation: /culo Response: El culo tuyo","title":"The culo command"},{"location":"userguide/#message-commands","text":"Official reference guide to message commands","title":"Message commands"},{"location":"userguide/#the-roulette-command","text":"Invocation: Select a message with a line-by-line list of elements. Click on the three dots > Applications > roulette. Response: A random line will be chosen from the message. ~~Striked lines~~ will not be processed Example image with request/response:","title":"The roulette command"}]}